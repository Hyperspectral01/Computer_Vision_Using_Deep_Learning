{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The Goal here is to take a folder of images (you can change the path to this folder in the code below) and process them into a csv file that has 48 values for every image (image is 256X256 and it is divided into 16 blocks of 64X64 , for every block 3 values-mode value for Red,mode value for Green, mode value for Blue in RGB, so a total of 16blocks X 3values = 48values + 1output_label (0 for class 1 and 1 for class 2 as an output label))"
      ],
      "metadata": {
        "id": "r4v-jwcvCol7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing all the dependencies"
      ],
      "metadata": {
        "id": "FzPvLYVaJmmk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2ld5WsqFmrw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sklearn.neural_network as skn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import csv\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taking all the images from the folder into images[]"
      ],
      "metadata": {
        "id": "D862QApMJsU8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CSV FILE CREATION**\n",
        "\n",
        "I have used a dataset having 100 images of agriculture (0 output label) and 100 images of airplane (1 otuput label). This is a subset of the dataset taken from https://www.kaggle.com/datasets/abdulhasibuddin/uc-merced-land-use-dataset\n",
        "The dataset folder has first 100 images of agriculture and next 100 of airplane.\n",
        "\n",
        "**Note**:You can use your own dataset, just change the path to the dataset folder in the code below"
      ],
      "metadata": {
        "id": "yE2ptLczEppu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "directory = '/content/drive/MyDrive/Colab Notebooks/Data/Dataset'\n",
        "\n",
        "images=[]\n",
        "for filename in os.listdir(directory):\n",
        "    images.append(cv2.imread('/content/drive/MyDrive/Colab Notebooks/Data/Dataset/'+filename))"
      ],
      "metadata": {
        "id": "4saISKLOHyer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basically i created a list of images"
      ],
      "metadata": {
        "id": "40lOlj5n4YNz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the shapes"
      ],
      "metadata": {
        "id": "Qy0YY1pFJyWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(images.size())\n",
        "type(images[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GrOW5F6J0lr",
        "outputId": "b8ce315d-ee8d-4f59-8b66-1106f88cfd54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now traversing through all the blocks and storing the data in a dictionary and then converted to a dataframe and finally to a csv"
      ],
      "metadata": {
        "id": "FUxIX99oMpTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/Data/airplanes_agriculture_dataset', 'w', newline='') as file:\n",
        "  writer=csv.writer(file)\n",
        "  count=0\n",
        "  for image in images:\n",
        "\n",
        "    #Creating a list of parameters to write for each image\n",
        "    data=[]\n",
        "\n",
        "    for row in range(0,4):\n",
        "      for col in range(0,4):\n",
        "\n",
        "        #Taking one block at a time\n",
        "        block=image[row*64:row*64+64,col*64:col*64+64]\n",
        "\n",
        "        counter_red=Counter()\n",
        "        counter_green=Counter()\n",
        "        counter_blue=Counter()\n",
        "\n",
        "        for block_row in block:\n",
        "          for pixel in block_row:\n",
        "            counter_red[pixel[0]]+=1\n",
        "            counter_green[pixel[1]]+=1\n",
        "            counter_blue[pixel[2]]+=1\n",
        "\n",
        "        #Now the counter stores the map of r's g's and b's in a block\n",
        "        mode_red=counter_red.most_common()[0][0]\n",
        "        mode_green=counter_green.most_common()[0][0]\n",
        "        mode_blue=counter_blue.most_common()[0][0]\n",
        "\n",
        "        data.append(mode_red)\n",
        "        data.append(mode_green)\n",
        "        data.append(mode_blue)\n",
        "        #Now we will move on to the next block and hence the data will be filled up with 16*3 values\n",
        "    if (count<=99):\n",
        "      data.append(0)\n",
        "    else:\n",
        "      data.append(1)\n",
        "    count+=1\n",
        "\n",
        "    #Now for the final act, we will write a row in the csv\n",
        "    print(data)\n",
        "    writer.writerow(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJCrHvcsM3Fd",
        "outputId": "9a1617c4-9e16-4720-f288-cb70681d5de3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[115, 120, 116, 122, 123, 122, 116, 121, 116, 112, 116, 114, 114, 123, 116, 115, 119, 115, 117, 125, 116, 117, 116, 116, 114, 122, 116, 111, 120, 118, 114, 125, 113, 110, 120, 112, 117, 125, 121, 120, 129, 116, 115, 123, 126, 110, 123, 120, 0]\n",
            "[115, 121, 116, 103, 123, 118, 111, 119, 119, 109, 116, 115, 114, 116, 119, 110, 117, 125, 107, 120, 116, 105, 122, 116, 109, 120, 120, 109, 124, 120, 107, 121, 120, 115, 121, 119, 112, 124, 113, 114, 119, 111, 105, 127, 117, 114, 123, 117, 0]\n",
            "[103, 120, 128, 111, 120, 115, 109, 118, 107, 108, 117, 107, 121, 126, 124, 111, 119, 122, 113, 121, 115, 113, 121, 110, 116, 121, 114, 109, 121, 112, 112, 119, 116, 115, 119, 115, 122, 127, 127, 119, 122, 116, 111, 114, 112, 118, 125, 125, 0]\n",
            "[193, 210, 220, 191, 209, 225, 194, 214, 236, 185, 43, 218, 140, 156, 253, 122, 135, 253, 149, 168, 184, 102, 125, 142, 123, 132, 138, 150, 168, 179, 148, 165, 178, 24, 40, 60, 160, 176, 191, 156, 173, 185, 149, 163, 176, 120, 139, 158, 0]\n",
            "[192, 225, 216, 192, 225, 216, 200, 227, 214, 162, 187, 181, 192, 221, 216, 192, 226, 216, 201, 226, 214, 201, 227, 216, 161, 207, 181, 192, 221, 216, 192, 221, 216, 201, 207, 216, 162, 191, 181, 162, 207, 181, 161, 207, 216, 183, 207, 210, 0]\n",
            "[112, 113, 98, 108, 111, 90, 110, 111, 90, 108, 109, 90, 110, 110, 90, 112, 110, 90, 109, 111, 90, 110, 109, 90, 107, 107, 90, 112, 106, 90, 107, 111, 90, 112, 111, 90, 110, 109, 90, 110, 108, 90, 109, 109, 90, 112, 109, 90, 0]\n",
            "[98, 104, 95, 91, 101, 84, 94, 106, 93, 93, 112, 92, 94, 107, 91, 95, 102, 95, 89, 98, 89, 98, 100, 96, 107, 111, 103, 95, 99, 92, 85, 99, 86, 98, 105, 91, 104, 120, 121, 97, 114, 102, 88, 99, 95, 91, 118, 91, 0]\n",
            "[81, 100, 95, 79, 100, 90, 93, 106, 89, 77, 101, 94, 77, 98, 96, 70, 84, 91, 99, 114, 94, 87, 103, 92, 81, 97, 96, 88, 102, 96, 89, 106, 98, 94, 115, 97, 92, 109, 97, 96, 104, 96, 93, 98, 98, 89, 118, 100, 0]\n",
            "[128, 155, 150, 128, 166, 150, 119, 166, 150, 128, 153, 154, 133, 166, 151, 128, 166, 150, 128, 166, 150, 128, 166, 156, 130, 166, 156, 131, 166, 151, 131, 166, 153, 128, 166, 150, 128, 166, 150, 128, 166, 150, 128, 166, 151, 128, 153, 149, 0]\n",
            "[112, 124, 112, 107, 119, 106, 109, 121, 109, 123, 130, 112, 111, 123, 109, 109, 121, 105, 108, 120, 103, 108, 132, 107, 103, 124, 105, 103, 121, 105, 111, 121, 108, 105, 128, 113, 111, 123, 108, 109, 121, 107, 107, 118, 102, 109, 123, 98, 0]\n",
            "[119, 167, 125, 120, 167, 96, 120, 167, 112, 120, 143, 96, 119, 167, 125, 120, 142, 96, 120, 154, 96, 120, 154, 96, 119, 167, 125, 119, 155, 96, 120, 154, 96, 120, 167, 96, 132, 167, 125, 147, 167, 130, 119, 167, 124, 119, 167, 124, 0]\n",
            "[116, 123, 118, 117, 122, 132, 116, 131, 132, 121, 128, 124, 108, 117, 106, 106, 118, 107, 106, 114, 104, 102, 115, 105, 107, 119, 107, 105, 115, 103, 104, 112, 103, 102, 113, 104, 107, 117, 107, 106, 111, 103, 101, 112, 101, 105, 112, 103, 0]\n",
            "[118, 131, 121, 125, 133, 131, 126, 140, 120, 119, 140, 123, 137, 161, 137, 129, 145, 120, 127, 141, 122, 138, 141, 132, 127, 138, 138, 145, 153, 130, 144, 135, 125, 170, 142, 153, 142, 138, 137, 135, 154, 146, 156, 154, 165, 162, 163, 153, 0]\n",
            "[73, 90, 75, 79, 92, 76, 90, 91, 81, 97, 96, 105, 78, 91, 76, 82, 96, 81, 103, 103, 113, 91, 99, 101, 74, 89, 70, 76, 93, 82, 77, 92, 72, 71, 92, 85, 73, 88, 75, 72, 92, 73, 76, 89, 73, 77, 92, 83, 0]\n",
            "[119, 168, 122, 119, 166, 128, 91, 166, 104, 91, 121, 111, 101, 123, 114, 91, 166, 98, 91, 114, 104, 119, 165, 113, 99, 165, 114, 92, 109, 98, 91, 109, 98, 119, 165, 113, 99, 120, 108, 91, 109, 97, 91, 168, 98, 119, 120, 108, 0]\n",
            "[132, 155, 156, 130, 153, 153, 129, 145, 150, 119, 145, 145, 130, 155, 154, 131, 145, 152, 129, 145, 150, 119, 145, 141, 134, 155, 157, 128, 145, 145, 128, 145, 145, 119, 141, 145, 131, 155, 151, 129, 145, 145, 119, 145, 145, 119, 145, 150, 0]\n",
            "[161, 166, 182, 161, 167, 182, 118, 168, 182, 118, 157, 170, 118, 166, 170, 161, 166, 170, 118, 156, 182, 118, 157, 170, 133, 166, 170, 145, 169, 182, 118, 166, 170, 118, 166, 170, 133, 167, 170, 145, 168, 182, 161, 166, 182, 133, 167, 170, 0]\n",
            "[109, 109, 90, 109, 109, 90, 109, 105, 82, 108, 108, 90, 109, 110, 90, 112, 107, 90, 109, 108, 82, 109, 109, 90, 112, 109, 90, 110, 107, 90, 110, 107, 90, 113, 112, 90, 112, 110, 90, 109, 111, 90, 112, 111, 90, 115, 110, 90, 0]\n",
            "[133, 155, 143, 133, 156, 142, 132, 155, 142, 132, 156, 141, 132, 152, 148, 131, 153, 143, 132, 152, 141, 132, 154, 141, 131, 152, 144, 130, 151, 138, 130, 150, 138, 130, 154, 138, 133, 154, 138, 132, 152, 130, 132, 155, 132, 134, 155, 138, 0]\n",
            "[116, 161, 152, 116, 166, 151, 138, 166, 149, 132, 166, 149, 116, 161, 151, 116, 161, 133, 132, 166, 149, 136, 166, 149, 116, 150, 128, 116, 150, 128, 116, 161, 128, 131, 160, 149, 116, 150, 128, 116, 150, 128, 116, 150, 128, 131, 150, 144, 0]\n",
            "[135, 166, 161, 135, 167, 161, 137, 160, 161, 138, 159, 160, 134, 157, 151, 134, 157, 150, 133, 159, 153, 134, 159, 151, 134, 150, 150, 132, 158, 150, 133, 158, 150, 131, 158, 151, 134, 150, 150, 132, 150, 151, 132, 150, 150, 130, 150, 150, 0]\n",
            "[98, 40, 42, 101, 131, 43, 115, 131, 44, 113, 47, 46, 105, 132, 44, 107, 122, 44, 121, 143, 39, 105, 39, 40, 107, 133, 38, 39, 37, 40, 120, 140, 42, 117, 130, 44, 109, 122, 130, 42, 39, 43, 117, 133, 46, 110, 149, 154, 0]\n",
            "[108, 148, 139, 129, 143, 142, 124, 140, 141, 123, 141, 144, 113, 134, 136, 123, 149, 144, 118, 144, 144, 121, 139, 147, 114, 134, 139, 130, 148, 148, 125, 140, 147, 119, 139, 145, 134, 134, 142, 131, 146, 149, 121, 143, 145, 124, 150, 148, 0]\n",
            "[94, 114, 111, 95, 122, 123, 96, 120, 107, 97, 120, 120, 96, 116, 99, 91, 112, 103, 96, 114, 95, 89, 119, 99, 95, 111, 100, 95, 104, 97, 92, 110, 98, 94, 113, 95, 95, 116, 94, 88, 113, 100, 91, 108, 97, 95, 122, 96, 0]\n",
            "[114, 114, 118, 118, 141, 124, 139, 154, 122, 125, 142, 118, 122, 137, 118, 119, 140, 118, 123, 151, 135, 116, 145, 133, 122, 140, 121, 113, 151, 110, 129, 166, 124, 119, 111, 124, 112, 138, 126, 108, 148, 108, 130, 145, 127, 129, 152, 130, 0]\n",
            "[112, 127, 117, 120, 139, 115, 115, 126, 115, 114, 128, 118, 114, 134, 122, 123, 133, 122, 119, 129, 112, 121, 127, 118, 115, 125, 115, 118, 137, 117, 117, 134, 122, 124, 135, 117, 121, 124, 116, 112, 126, 114, 121, 128, 119, 119, 131, 120, 0]\n",
            "[146, 148, 133, 151, 149, 141, 147, 154, 141, 161, 156, 142, 147, 149, 132, 150, 151, 137, 147, 159, 150, 158, 165, 150, 142, 143, 133, 151, 151, 134, 152, 154, 146, 155, 163, 150, 142, 150, 135, 137, 149, 133, 147, 146, 144, 152, 153, 146, 0]\n",
            "[144, 165, 153, 147, 165, 152, 143, 169, 152, 145, 168, 161, 141, 166, 154, 147, 170, 153, 147, 169, 153, 146, 169, 168, 144, 166, 158, 148, 170, 158, 147, 171, 169, 147, 176, 168, 150, 172, 167, 148, 171, 170, 148, 170, 169, 147, 177, 169, 0]\n",
            "[118, 138, 125, 120, 137, 125, 119, 138, 124, 119, 139, 122, 120, 137, 124, 118, 136, 123, 120, 140, 123, 120, 137, 124, 118, 141, 124, 119, 141, 123, 122, 139, 125, 116, 138, 122, 121, 139, 127, 118, 139, 124, 122, 142, 129, 117, 140, 125, 0]\n",
            "[147, 170, 182, 146, 170, 182, 161, 186, 182, 147, 169, 182, 146, 169, 182, 145, 169, 182, 146, 169, 170, 133, 169, 169, 135, 167, 161, 133, 149, 150, 131, 154, 150, 131, 150, 150, 135, 155, 153, 134, 166, 169, 136, 166, 150, 132, 155, 143, 0]\n",
            "[162, 207, 179, 162, 170, 167, 161, 190, 166, 152, 181, 158, 162, 186, 167, 152, 170, 161, 152, 182, 161, 143, 176, 150, 152, 184, 159, 152, 179, 152, 135, 170, 148, 147, 171, 146, 152, 170, 150, 145, 170, 148, 143, 169, 148, 147, 178, 166, 0]\n",
            "[133, 130, 122, 123, 138, 124, 120, 135, 123, 117, 130, 114, 129, 140, 129, 129, 137, 114, 113, 136, 123, 119, 132, 117, 130, 137, 123, 117, 128, 113, 116, 138, 115, 121, 127, 123, 122, 130, 118, 119, 128, 115, 116, 130, 108, 126, 126, 123, 0]\n",
            "[87, 95, 69, 81, 97, 67, 83, 95, 67, 80, 96, 70, 85, 99, 74, 87, 98, 67, 90, 96, 66, 81, 97, 66, 90, 100, 69, 82, 96, 69, 81, 95, 69, 81, 95, 72, 84, 97, 66, 89, 100, 70, 87, 97, 69, 80, 96, 68, 0]\n",
            "[128, 165, 141, 132, 147, 126, 120, 147, 126, 121, 166, 126, 131, 150, 129, 128, 150, 127, 128, 150, 129, 131, 151, 129, 128, 150, 131, 128, 150, 128, 133, 150, 127, 133, 167, 129, 125, 148, 128, 131, 148, 128, 136, 167, 135, 145, 167, 140, 0]\n",
            "[107, 157, 161, 120, 156, 161, 151, 156, 161, 107, 156, 160, 107, 157, 161, 107, 156, 161, 146, 156, 161, 119, 150, 144, 107, 156, 161, 119, 165, 142, 119, 165, 145, 119, 155, 145, 119, 142, 142, 119, 166, 156, 119, 150, 142, 128, 150, 142, 0]\n",
            "[137, 169, 150, 137, 166, 143, 137, 169, 151, 136, 166, 150, 137, 166, 151, 137, 169, 151, 133, 166, 143, 141, 166, 143, 137, 166, 150, 132, 166, 150, 143, 169, 150, 139, 169, 143, 130, 166, 149, 136, 166, 151, 143, 169, 150, 143, 169, 147, 0]\n",
            "[118, 116, 136, 117, 123, 138, 118, 137, 140, 121, 126, 143, 120, 121, 135, 114, 121, 131, 119, 120, 139, 119, 122, 142, 119, 117, 133, 123, 124, 137, 120, 142, 139, 122, 125, 142, 116, 120, 134, 115, 114, 136, 117, 121, 138, 118, 122, 141, 0]\n",
            "[147, 166, 138, 133, 166, 129, 137, 165, 138, 134, 165, 138, 147, 166, 143, 137, 166, 133, 119, 165, 127, 128, 150, 129, 143, 165, 143, 147, 166, 141, 133, 168, 138, 131, 160, 138, 138, 165, 142, 147, 165, 138, 139, 166, 137, 131, 156, 129, 0]\n",
            "[80, 96, 80, 75, 92, 86, 99, 103, 103, 92, 99, 113, 77, 95, 73, 88, 97, 79, 74, 94, 81, 82, 96, 88, 79, 94, 73, 80, 92, 77, 102, 95, 94, 82, 99, 105, 74, 94, 77, 70, 98, 77, 94, 102, 92, 73, 84, 76, 0]\n",
            "[118, 166, 126, 119, 166, 127, 119, 166, 127, 118, 166, 127, 119, 166, 126, 119, 168, 126, 119, 166, 126, 119, 166, 127, 119, 168, 127, 119, 168, 127, 119, 168, 126, 119, 168, 126, 119, 166, 126, 119, 166, 127, 119, 168, 126, 119, 147, 127, 0]\n",
            "[144, 145, 139, 142, 146, 62, 149, 144, 141, 149, 139, 140, 151, 161, 147, 149, 158, 152, 144, 148, 136, 153, 63, 143, 147, 166, 157, 150, 158, 148, 153, 160, 147, 145, 150, 138, 153, 144, 162, 159, 156, 174, 153, 157, 152, 154, 150, 143, 0]\n",
            "[126, 137, 125, 119, 133, 121, 125, 133, 122, 113, 130, 116, 123, 134, 128, 123, 134, 122, 119, 140, 129, 123, 136, 125, 121, 136, 123, 123, 134, 123, 123, 136, 123, 124, 144, 121, 122, 137, 121, 127, 141, 132, 118, 143, 123, 133, 136, 127, 0]\n",
            "[122, 156, 116, 122, 162, 115, 122, 156, 115, 119, 153, 119, 122, 152, 116, 125, 157, 120, 134, 168, 123, 133, 168, 119, 123, 163, 121, 134, 169, 121, 135, 169, 121, 133, 168, 121, 123, 157, 123, 133, 169, 121, 136, 169, 121, 133, 168, 125, 0]\n",
            "[160, 194, 182, 160, 193, 188, 160, 188, 181, 160, 193, 182, 160, 189, 181, 160, 186, 182, 160, 192, 187, 160, 193, 181, 160, 192, 167, 160, 169, 181, 160, 169, 167, 160, 188, 182, 160, 192, 181, 160, 177, 183, 160, 177, 181, 149, 166, 182, 0]\n",
            "[127, 134, 136, 128, 136, 128, 131, 138, 135, 123, 137, 139, 121, 133, 121, 124, 143, 135, 125, 122, 126, 125, 141, 141, 124, 135, 122, 124, 132, 129, 119, 147, 145, 133, 132, 140, 117, 132, 116, 127, 132, 135, 124, 138, 145, 122, 136, 143, 0]\n",
            "[138, 166, 138, 130, 166, 138, 119, 153, 134, 132, 166, 138, 129, 166, 142, 133, 166, 138, 133, 166, 133, 119, 166, 138, 128, 166, 127, 119, 166, 142, 119, 154, 138, 137, 166, 142, 138, 166, 137, 119, 150, 134, 119, 166, 127, 132, 166, 142, 0]\n",
            "[160, 188, 183, 160, 206, 213, 160, 207, 213, 160, 207, 189, 160, 183, 183, 160, 207, 189, 177, 207, 215, 160, 207, 184, 160, 192, 183, 160, 207, 189, 160, 207, 212, 160, 197, 189, 160, 206, 212, 182, 206, 217, 180, 214, 217, 186, 218, 217, 0]\n",
            "[90, 110, 96, 94, 110, 93, 98, 121, 103, 93, 114, 99, 82, 87, 99, 87, 116, 97, 89, 112, 97, 92, 117, 100, 86, 107, 94, 93, 112, 93, 87, 114, 98, 84, 109, 96, 84, 111, 96, 84, 102, 98, 94, 111, 94, 91, 115, 97, 0]\n",
            "[90, 95, 97, 76, 99, 86, 76, 96, 96, 99, 99, 99, 90, 101, 100, 83, 99, 100, 78, 101, 94, 94, 101, 103, 86, 98, 92, 82, 99, 98, 70, 98, 77, 85, 102, 98, 80, 93, 85, 81, 100, 101, 79, 91, 80, 80, 97, 78, 0]\n",
            "[119, 142, 137, 119, 136, 129, 119, 135, 130, 119, 150, 131, 119, 150, 137, 119, 150, 140, 119, 141, 137, 119, 150, 137, 119, 150, 142, 119, 166, 153, 119, 167, 137, 119, 167, 140, 119, 152, 137, 119, 151, 140, 119, 167, 137, 119, 167, 158, 0]\n",
            "[119, 167, 144, 119, 167, 160, 118, 170, 170, 146, 170, 169, 138, 167, 161, 133, 167, 161, 133, 167, 169, 133, 167, 154, 146, 167, 162, 119, 167, 161, 119, 167, 161, 133, 167, 161, 151, 169, 162, 119, 167, 144, 119, 167, 151, 118, 167, 169, 0]\n",
            "[87, 86, 88, 97, 103, 106, 106, 105, 106, 94, 98, 102, 90, 84, 92, 106, 106, 107, 103, 102, 107, 103, 99, 110, 92, 100, 96, 99, 103, 107, 105, 105, 110, 96, 98, 104, 96, 101, 96, 95, 102, 101, 108, 110, 106, 99, 95, 101, 0]\n",
            "[119, 155, 125, 128, 167, 125, 133, 167, 125, 133, 167, 125, 120, 152, 110, 118, 167, 125, 133, 167, 125, 138, 170, 125, 120, 156, 112, 119, 151, 112, 132, 167, 125, 149, 170, 125, 119, 154, 119, 119, 152, 121, 119, 167, 125, 161, 167, 125, 0]\n",
            "[160, 189, 181, 160, 169, 181, 148, 169, 166, 118, 169, 151, 160, 197, 187, 160, 191, 181, 149, 169, 166, 148, 166, 155, 160, 197, 187, 160, 197, 181, 149, 169, 166, 149, 166, 155, 160, 197, 181, 160, 188, 181, 151, 169, 166, 143, 166, 152, 0]\n",
            "[160, 192, 181, 160, 192, 181, 160, 188, 166, 149, 169, 166, 160, 206, 181, 160, 195, 181, 160, 195, 181, 160, 192, 180, 160, 189, 181, 160, 188, 181, 160, 186, 181, 160, 189, 181, 160, 187, 181, 160, 192, 181, 160, 192, 181, 160, 189, 181, 0]\n",
            "[119, 165, 126, 119, 165, 126, 119, 168, 154, 161, 168, 157, 120, 168, 126, 162, 168, 126, 162, 168, 97, 162, 168, 126, 119, 168, 126, 162, 168, 126, 162, 168, 126, 162, 168, 126, 162, 168, 126, 162, 168, 147, 162, 168, 126, 162, 168, 126, 0]\n",
            "[169, 165, 152, 160, 166, 139, 148, 157, 143, 152, 151, 138, 156, 167, 144, 154, 156, 141, 163, 161, 157, 161, 162, 140, 159, 167, 154, 161, 158, 150, 162, 169, 157, 161, 152, 144, 170, 168, 149, 167, 162, 151, 166, 159, 147, 161, 157, 147, 0]\n",
            "[78, 93, 65, 81, 97, 65, 79, 97, 65, 77, 94, 66, 76, 94, 66, 82, 96, 67, 80, 98, 69, 79, 91, 68, 83, 98, 68, 79, 98, 67, 77, 96, 67, 79, 95, 66, 77, 95, 68, 77, 96, 67, 80, 96, 64, 79, 97, 63, 0]\n",
            "[140, 167, 169, 142, 167, 169, 119, 167, 169, 136, 167, 161, 119, 167, 169, 135, 167, 151, 133, 155, 151, 135, 158, 150, 119, 166, 150, 133, 156, 150, 134, 157, 149, 133, 158, 152, 119, 166, 143, 119, 159, 148, 134, 159, 149, 136, 167, 153, 0]\n",
            "[123, 130, 116, 119, 133, 120, 120, 130, 117, 123, 134, 124, 117, 131, 120, 111, 123, 110, 121, 129, 117, 118, 130, 115, 117, 129, 121, 113, 129, 114, 115, 133, 117, 124, 128, 114, 117, 124, 114, 115, 130, 114, 125, 137, 112, 114, 137, 122, 0]\n",
            "[119, 153, 134, 119, 150, 134, 119, 150, 128, 119, 150, 133, 119, 150, 142, 119, 150, 128, 119, 146, 128, 119, 142, 128, 119, 156, 142, 119, 150, 140, 119, 150, 128, 119, 146, 128, 119, 155, 140, 119, 146, 134, 119, 150, 134, 119, 147, 128, 0]\n",
            "[115, 131, 108, 125, 146, 160, 127, 139, 123, 119, 150, 158, 112, 139, 107, 121, 141, 119, 127, 152, 172, 131, 151, 158, 107, 140, 158, 122, 142, 104, 135, 144, 163, 132, 156, 164, 118, 142, 173, 131, 142, 111, 137, 150, 159, 139, 153, 163, 0]\n",
            "[109, 125, 112, 112, 124, 114, 108, 129, 108, 113, 123, 113, 108, 126, 112, 114, 126, 111, 113, 124, 112, 118, 124, 116, 111, 123, 112, 108, 124, 107, 113, 124, 118, 118, 125, 114, 111, 120, 115, 112, 125, 109, 114, 126, 118, 122, 126, 113, 0]\n",
            "[133, 168, 121, 134, 168, 120, 133, 168, 120, 138, 171, 123, 131, 152, 111, 132, 168, 121, 133, 168, 122, 146, 171, 130, 120, 152, 111, 134, 168, 118, 136, 168, 121, 146, 171, 123, 132, 168, 118, 120, 168, 111, 134, 168, 122, 152, 171, 136, 0]\n",
            "[117, 114, 113, 134, 133, 131, 143, 133, 132, 146, 149, 144, 124, 116, 112, 114, 110, 108, 119, 116, 112, 107, 118, 106, 106, 107, 105, 100, 108, 109, 111, 110, 107, 108, 117, 100, 99, 106, 97, 99, 102, 95, 105, 110, 99, 101, 113, 129, 0]\n",
            "[127, 148, 130, 126, 147, 128, 127, 148, 128, 127, 149, 134, 129, 147, 129, 127, 147, 128, 128, 148, 129, 129, 149, 132, 127, 147, 130, 128, 146, 128, 129, 148, 130, 128, 148, 133, 126, 146, 127, 126, 146, 127, 129, 145, 131, 128, 147, 131, 0]\n",
            "[159, 207, 189, 159, 207, 207, 160, 206, 207, 160, 207, 207, 160, 207, 189, 160, 207, 184, 160, 167, 184, 159, 207, 184, 160, 206, 189, 160, 206, 208, 160, 207, 189, 159, 207, 196, 160, 197, 188, 160, 207, 183, 117, 207, 182, 160, 206, 184, 0]\n",
            "[163, 183, 170, 164, 166, 170, 163, 174, 163, 165, 173, 150, 162, 167, 180, 162, 193, 182, 151, 171, 160, 163, 171, 170, 161, 166, 180, 161, 166, 150, 162, 167, 181, 162, 167, 182, 161, 166, 152, 161, 166, 152, 161, 166, 151, 162, 167, 151, 0]\n",
            "[132, 146, 155, 114, 126, 126, 112, 115, 120, 21, 0, 0, 135, 142, 151, 114, 0, 134, 109, 112, 120, 21, 0, 0, 125, 139, 149, 123, 138, 145, 114, 0, 0, 21, 0, 0, 141, 143, 152, 131, 141, 142, 120, 129, 136, 21, 0, 0, 0]\n",
            "[141, 152, 163, 139, 192, 185, 163, 185, 192, 161, 180, 192, 147, 192, 185, 158, 180, 192, 163, 185, 192, 160, 180, 192, 164, 185, 192, 164, 185, 192, 164, 185, 197, 163, 185, 192, 163, 185, 192, 166, 185, 197, 163, 179, 185, 160, 177, 192, 0]\n",
            "[172, 190, 179, 184, 191, 181, 190, 200, 184, 202, 207, 189, 176, 190, 172, 181, 191, 178, 186, 197, 181, 187, 199, 182, 107, 131, 129, 181, 191, 179, 190, 202, 187, 192, 200, 186, 184, 197, 182, 188, 200, 185, 189, 199, 183, 193, 206, 190, 0]\n",
            "[176, 190, 178, 82, 101, 105, 88, 103, 109, 81, 99, 104, 174, 191, 178, 176, 191, 178, 173, 190, 176, 172, 189, 180, 174, 193, 183, 172, 189, 180, 175, 194, 182, 177, 191, 180, 169, 190, 178, 95, 117, 123, 97, 119, 121, 94, 116, 124, 0]\n",
            "[178, 190, 175, 171, 172, 0, 174, 180, 171, 197, 204, 186, 174, 187, 172, 255, 183, 168, 183, 194, 180, 211, 215, 196, 173, 184, 169, 170, 185, 174, 177, 188, 174, 204, 208, 194, 146, 158, 0, 255, 252, 172, 174, 191, 173, 209, 214, 193, 0]\n",
            "[86, 99, 94, 90, 103, 100, 81, 97, 97, 86, 102, 163, 87, 104, 95, 87, 103, 0, 80, 98, 0, 80, 99, 92, 85, 99, 90, 86, 103, 93, 84, 99, 91, 87, 98, 94, 76, 93, 82, 86, 98, 88, 78, 91, 85, 78, 94, 86, 0]\n",
            "[169, 172, 170, 176, 189, 175, 186, 196, 181, 193, 204, 184, 176, 194, 176, 177, 191, 179, 170, 187, 178, 180, 194, 182, 173, 186, 178, 183, 198, 178, 184, 199, 182, 184, 198, 183, 150, 161, 149, 179, 192, 181, 184, 195, 182, 176, 193, 181, 0]\n",
            "[80, 97, 95, 138, 165, 161, 87, 113, 0, 85, 107, 107, 44, 50, 48, 255, 23, 0, 16, 9, 0, 146, 168, 160, 38, 45, 36, 165, 186, 170, 162, 187, 166, 147, 173, 163, 161, 186, 172, 161, 182, 174, 155, 172, 163, 146, 172, 162, 0]\n",
            "[158, 176, 192, 150, 170, 185, 136, 156, 171, 131, 150, 164, 146, 172, 185, 142, 164, 185, 131, 0, 0, 123, 0, 0, 139, 164, 185, 143, 167, 185, 141, 0, 192, 117, 0, 0, 143, 172, 185, 136, 0, 185, 26, 0, 0, 26, 0, 0, 0]\n",
            "[129, 131, 139, 142, 135, 146, 138, 135, 147, 142, 135, 143, 133, 131, 130, 142, 131, 146, 142, 137, 142, 142, 135, 130, 140, 131, 139, 142, 131, 137, 142, 135, 148, 144, 137, 145, 142, 134, 142, 144, 142, 146, 140, 139, 148, 144, 139, 150, 0]\n",
            "[152, 155, 174, 154, 160, 174, 152, 160, 174, 153, 157, 177, 150, 157, 174, 155, 160, 174, 154, 158, 174, 148, 157, 174, 152, 160, 174, 152, 163, 174, 152, 158, 174, 153, 160, 177, 156, 160, 179, 155, 160, 179, 152, 163, 174, 153, 163, 177, 0]\n",
            "[100, 91, 91, 105, 93, 94, 107, 96, 104, 105, 94, 101, 100, 89, 90, 107, 96, 96, 102, 88, 104, 105, 93, 106, 99, 87, 94, 103, 86, 97, 111, 92, 92, 112, 96, 104, 105, 89, 96, 109, 103, 99, 109, 99, 102, 112, 99, 105, 0]\n",
            "[178, 193, 179, 120, 152, 171, 171, 182, 175, 102, 114, 105, 177, 189, 174, 179, 189, 175, 179, 188, 177, 176, 191, 180, 189, 199, 183, 170, 180, 0, 175, 183, 176, 173, 187, 175, 173, 188, 176, 180, 193, 180, 178, 194, 180, 16, 7, 0, 0]\n",
            "[136, 145, 127, 134, 138, 130, 124, 139, 143, 124, 138, 134, 138, 136, 129, 136, 138, 137, 129, 125, 123, 136, 138, 141, 136, 138, 134, 122, 140, 129, 134, 131, 130, 138, 138, 130, 136, 137, 132, 129, 126, 141, 136, 135, 141, 148, 152, 148, 0]\n",
            "[109, 100, 102, 108, 99, 102, 113, 105, 108, 114, 105, 105, 111, 100, 101, 112, 102, 107, 116, 104, 107, 118, 106, 107, 110, 101, 103, 109, 99, 102, 114, 104, 106, 115, 103, 106, 110, 101, 103, 112, 101, 105, 115, 103, 107, 117, 107, 107, 0]\n",
            "[107, 110, 119, 109, 111, 119, 107, 118, 116, 109, 118, 124, 109, 110, 121, 107, 115, 119, 109, 120, 124, 114, 118, 122, 105, 110, 119, 109, 111, 121, 105, 120, 122, 109, 118, 122, 105, 110, 119, 105, 108, 121, 103, 118, 122, 110, 120, 122, 0]\n",
            "[80, 91, 83, 81, 93, 0, 86, 102, 95, 83, 103, 91, 90, 114, 110, 255, 94, 0, 15, 4, 0, 85, 103, 97, 90, 109, 105, 90, 105, 0, 85, 97, 0, 94, 110, 100, 88, 100, 93, 89, 101, 94, 86, 96, 85, 85, 101, 97, 0]\n",
            "[159, 164, 69, 159, 156, 76, 159, 161, 162, 153, 153, 147, 162, 76, 151, 159, 158, 75, 159, 82, 159, 159, 82, 152, 152, 73, 69, 159, 161, 149, 156, 155, 149, 157, 161, 69, 78, 77, 141, 81, 80, 72, 78, 82, 76, 152, 159, 69, 0]\n",
            "[191, 197, 197, 99, 122, 116, 96, 119, 112, 91, 114, 103, 193, 197, 197, 196, 200, 200, 255, 255, 255, 91, 114, 175, 194, 195, 195, 193, 205, 215, 192, 203, 211, 183, 197, 200, 207, 226, 233, 187, 186, 206, 191, 204, 214, 191, 206, 214, 0]\n",
            "[146, 161, 176, 162, 174, 185, 87, 100, 98, 93, 104, 122, 146, 162, 178, 147, 166, 185, 160, 252, 185, 164, 185, 192, 145, 161, 176, 252, 252, 252, 154, 173, 185, 164, 185, 192, 111, 111, 117, 154, 173, 185, 160, 179, 192, 158, 178, 192, 0]\n",
            "[183, 193, 174, 191, 198, 182, 186, 197, 181, 210, 210, 191, 175, 186, 170, 173, 179, 165, 181, 191, 0, 181, 188, 175, 173, 181, 168, 249, 250, 0, 172, 188, 172, 178, 189, 172, 166, 176, 0, 175, 187, 171, 175, 182, 171, 180, 191, 175, 0]\n",
            "[125, 132, 125, 125, 130, 123, 123, 127, 119, 125, 126, 119, 128, 132, 124, 127, 129, 125, 122, 131, 119, 123, 129, 119, 124, 132, 122, 123, 133, 119, 120, 127, 118, 122, 130, 117, 126, 129, 124, 122, 129, 122, 123, 132, 116, 121, 130, 121, 0]\n",
            "[136, 157, 165, 119, 123, 132, 117, 135, 141, 143, 162, 176, 139, 157, 166, 247, 0, 0, 156, 170, 176, 151, 185, 185, 145, 162, 171, 126, 134, 139, 125, 141, 151, 126, 143, 150, 143, 161, 169, 143, 158, 171, 139, 151, 162, 141, 160, 162, 0]\n",
            "[77, 90, 95, 74, 95, 102, 87, 111, 110, 88, 121, 121, 57, 70, 78, 7, 1, 0, 72, 91, 92, 83, 112, 113, 64, 68, 73, 62, 1, 0, 60, 1, 0, 62, 69, 70, 87, 110, 117, 63, 68, 74, 66, 74, 79, 66, 78, 84, 0]\n",
            "[164, 159, 157, 169, 180, 166, 178, 190, 170, 177, 190, 175, 166, 179, 0, 13, 1, 0, 178, 189, 173, 181, 192, 176, 168, 176, 164, 164, 171, 165, 180, 191, 173, 186, 198, 177, 166, 183, 177, 143, 163, 157, 174, 186, 172, 186, 197, 181, 0]\n",
            "[158, 74, 144, 158, 73, 66, 71, 69, 66, 158, 73, 66, 72, 69, 63, 74, 73, 66, 153, 73, 66, 156, 69, 147, 153, 155, 64, 71, 74, 66, 74, 76, 73, 156, 76, 67, 160, 73, 81, 164, 76, 72, 156, 76, 152, 153, 155, 66, 0]\n",
            "[154, 78, 73, 79, 78, 72, 82, 77, 73, 79, 77, 73, 152, 77, 73, 154, 80, 73, 149, 146, 143, 82, 80, 73, 152, 77, 73, 155, 77, 73, 80, 151, 143, 149, 148, 143, 77, 78, 73, 79, 80, 76, 152, 77, 73, 82, 77, 76, 0]\n",
            "[114, 121, 116, 113, 120, 118, 112, 120, 116, 116, 123, 119, 113, 120, 114, 112, 120, 119, 114, 123, 114, 115, 124, 120, 113, 120, 117, 113, 121, 117, 115, 122, 120, 118, 123, 123, 115, 120, 116, 117, 124, 115, 117, 123, 120, 117, 125, 122, 0]\n",
            "[94, 91, 82, 97, 91, 82, 99, 93, 83, 101, 98, 84, 96, 92, 81, 95, 91, 79, 99, 94, 82, 101, 96, 85, 96, 89, 77, 95, 88, 80, 97, 90, 82, 99, 90, 85, 92, 86, 79, 95, 87, 80, 97, 90, 81, 99, 91, 83, 0]\n",
            "[92, 114, 97, 98, 114, 97, 100, 123, 97, 91, 114, 98, 92, 114, 97, 99, 114, 97, 92, 109, 97, 91, 109, 97, 103, 123, 98, 102, 123, 97, 99, 166, 97, 99, 114, 98, 92, 109, 97, 100, 166, 97, 99, 166, 97, 100, 123, 98, 0]\n",
            "[103, 89, 91, 109, 95, 97, 104, 94, 95, 105, 94, 96, 102, 89, 91, 99, 93, 94, 101, 92, 93, 104, 93, 94, 103, 89, 91, 105, 93, 94, 104, 92, 94, 104, 94, 95, 103, 90, 92, 106, 92, 95, 100, 93, 95, 102, 93, 94, 0]\n",
            "[194, 199, 184, 185, 195, 179, 164, 172, 165, 152, 156, 153, 189, 199, 183, 177, 188, 169, 164, 170, 163, 150, 155, 152, 170, 180, 0, 168, 180, 166, 16, 6, 0, 163, 171, 0, 102, 118, 105, 100, 116, 0, 172, 179, 172, 15, 4, 0, 0]\n",
            "[109, 128, 120, 109, 130, 122, 114, 132, 125, 114, 130, 125, 186, 198, 179, 91, 128, 61, 93, 130, 65, 93, 134, 65, 178, 189, 171, 185, 195, 177, 186, 199, 175, 185, 194, 178, 199, 205, 185, 197, 203, 184, 199, 199, 186, 184, 194, 174, 1]\n",
            "[124, 111, 119, 119, 108, 118, 125, 116, 119, 123, 108, 120, 130, 118, 123, 124, 115, 117, 126, 115, 127, 123, 107, 116, 128, 121, 126, 128, 118, 128, 130, 124, 132, 132, 119, 128, 131, 121, 125, 134, 122, 130, 129, 124, 132, 131, 122, 126, 1]\n",
            "[158, 169, 185, 162, 185, 185, 160, 173, 173, 165, 185, 192, 161, 173, 185, 142, 152, 161, 155, 185, 185, 185, 197, 197, 126, 142, 152, 36, 0, 0, 146, 155, 165, 126, 139, 150, 39, 0, 0, 139, 157, 166, 132, 152, 165, 126, 138, 147, 1]\n",
            "[188, 200, 184, 190, 201, 184, 173, 13, 0, 148, 159, 0, 183, 195, 185, 176, 190, 180, 172, 179, 173, 153, 169, 166, 194, 206, 190, 183, 196, 183, 171, 189, 171, 156, 169, 167, 188, 200, 184, 180, 194, 179, 254, 253, 0, 144, 164, 163, 1]\n",
            "[124, 138, 124, 123, 138, 121, 124, 139, 124, 125, 143, 125, 125, 137, 119, 123, 138, 125, 121, 139, 122, 123, 140, 121, 122, 134, 123, 121, 138, 124, 120, 138, 123, 123, 138, 124, 124, 136, 126, 123, 136, 119, 122, 137, 120, 125, 139, 125, 1]\n",
            "[143, 152, 172, 148, 152, 172, 149, 155, 174, 149, 152, 169, 145, 152, 169, 148, 152, 172, 154, 157, 174, 152, 158, 174, 148, 152, 174, 148, 152, 174, 152, 158, 174, 154, 157, 174, 150, 157, 172, 148, 157, 174, 152, 160, 177, 154, 160, 169, 1]\n",
            "[151, 162, 173, 156, 156, 183, 255, 255, 98, 97, 115, 98, 158, 173, 185, 153, 243, 239, 255, 255, 159, 96, 115, 98, 147, 162, 174, 255, 255, 255, 142, 144, 151, 93, 230, 100, 146, 164, 177, 150, 163, 170, 142, 147, 156, 191, 200, 206, 1]\n",
            "[143, 141, 131, 139, 142, 130, 150, 153, 144, 156, 158, 153, 141, 143, 129, 146, 148, 132, 154, 154, 147, 165, 153, 152, 146, 140, 133, 148, 150, 128, 147, 147, 142, 159, 152, 146, 141, 144, 137, 144, 143, 131, 148, 144, 133, 151, 144, 137, 1]\n",
            "[111, 112, 92, 98, 117, 92, 112, 111, 91, 110, 113, 91, 111, 116, 92, 100, 103, 91, 99, 102, 91, 112, 99, 91, 111, 112, 92, 97, 103, 91, 99, 100, 91, 112, 107, 91, 100, 99, 92, 97, 115, 85, 101, 99, 91, 91, 99, 91, 1]\n",
            "[143, 154, 155, 143, 154, 155, 57, 154, 155, 66, 154, 155, 143, 154, 146, 146, 154, 155, 145, 154, 146, 129, 154, 140, 145, 154, 149, 148, 80, 151, 148, 154, 155, 63, 154, 145, 145, 160, 155, 147, 154, 137, 146, 155, 155, 142, 156, 143, 1]\n",
            "[143, 149, 169, 140, 143, 162, 138, 145, 162, 140, 145, 162, 143, 152, 167, 140, 145, 165, 140, 147, 162, 143, 147, 162, 143, 152, 164, 138, 145, 162, 138, 144, 162, 143, 149, 167, 146, 147, 171, 143, 145, 162, 138, 145, 167, 140, 147, 167, 1]\n",
            "[81, 169, 158, 166, 175, 164, 166, 177, 160, 167, 173, 161, 88, 96, 0, 5, 0, 0, 8, 0, 0, 82, 93, 86, 84, 93, 89, 255, 89, 79, 73, 80, 74, 80, 87, 80, 75, 84, 77, 7, 2, 0, 69, 76, 0, 80, 87, 84, 1]\n",
            "[109, 128, 120, 109, 130, 122, 114, 132, 125, 114, 130, 125, 186, 198, 179, 91, 128, 61, 93, 130, 65, 93, 134, 65, 178, 189, 171, 185, 195, 177, 186, 199, 175, 185, 194, 178, 199, 205, 185, 197, 203, 184, 199, 199, 186, 184, 194, 174, 1]\n",
            "[193, 208, 194, 180, 192, 194, 91, 85, 86, 93, 86, 86, 199, 210, 209, 255, 255, 207, 255, 255, 197, 89, 86, 78, 192, 203, 201, 193, 203, 200, 190, 200, 199, 185, 197, 197, 95, 105, 101, 90, 104, 197, 190, 200, 200, 192, 203, 203, 1]\n",
            "[182, 192, 175, 183, 193, 177, 182, 192, 176, 185, 193, 179, 181, 191, 163, 180, 173, 0, 173, 184, 172, 183, 193, 177, 165, 176, 166, 164, 168, 0, 166, 179, 169, 162, 170, 161, 23, 16, 0, 23, 16, 0, 147, 166, 155, 170, 184, 168, 1]\n",
            "[148, 155, 140, 147, 155, 140, 150, 156, 155, 149, 140, 84, 148, 155, 155, 149, 153, 140, 151, 158, 140, 151, 140, 140, 147, 153, 155, 147, 151, 155, 147, 140, 140, 147, 155, 158, 146, 153, 140, 150, 156, 140, 148, 158, 161, 148, 140, 140, 1]\n",
            "[161, 193, 141, 163, 194, 137, 163, 193, 141, 163, 194, 137, 161, 182, 125, 162, 167, 137, 163, 167, 137, 163, 193, 140, 163, 185, 125, 163, 189, 137, 163, 167, 135, 163, 170, 129, 163, 185, 130, 163, 188, 137, 163, 167, 124, 163, 170, 129, 1]\n",
            "[150, 167, 161, 171, 175, 167, 173, 178, 174, 177, 169, 170, 150, 154, 161, 157, 169, 159, 177, 175, 161, 162, 175, 177, 150, 157, 153, 168, 164, 161, 160, 166, 161, 162, 172, 170, 150, 164, 141, 150, 151, 156, 150, 159, 151, 152, 146, 154, 1]\n",
            "[88, 133, 165, 91, 138, 175, 83, 104, 131, 107, 135, 163, 90, 132, 172, 94, 134, 174, 84, 106, 131, 109, 133, 160, 87, 128, 169, 86, 139, 176, 83, 107, 130, 109, 133, 162, 84, 123, 164, 94, 146, 180, 86, 108, 134, 109, 133, 160, 1]\n",
            "[162, 183, 152, 162, 169, 148, 162, 169, 140, 162, 188, 152, 162, 186, 149, 162, 166, 125, 162, 187, 164, 162, 207, 164, 162, 184, 151, 162, 169, 141, 162, 188, 164, 162, 206, 158, 162, 166, 153, 163, 183, 147, 162, 187, 148, 162, 187, 151, 1]\n",
            "[146, 162, 171, 112, 123, 128, 126, 134, 156, 156, 170, 185, 143, 160, 170, 111, 115, 125, 146, 162, 165, 157, 185, 185, 142, 0, 0, 252, 0, 0, 145, 164, 166, 150, 185, 185, 136, 157, 165, 119, 125, 132, 117, 126, 141, 143, 162, 176, 1]\n",
            "[118, 166, 159, 160, 186, 165, 160, 187, 165, 118, 169, 126, 118, 169, 142, 160, 169, 165, 160, 184, 165, 118, 169, 159, 118, 169, 157, 157, 184, 160, 118, 169, 160, 118, 169, 158, 118, 169, 148, 118, 179, 165, 160, 169, 165, 118, 166, 165, 1]\n",
            "[96, 135, 192, 94, 136, 189, 96, 131, 175, 89, 130, 164, 101, 152, 189, 96, 151, 191, 93, 144, 176, 92, 130, 169, 98, 149, 188, 99, 154, 188, 89, 136, 187, 91, 131, 166, 98, 154, 189, 98, 146, 183, 93, 141, 184, 86, 134, 172, 1]\n",
            "[182, 196, 206, 174, 192, 203, 131, 129, 131, 95, 104, 105, 194, 211, 217, 177, 187, 197, 175, 192, 204, 128, 126, 127, 137, 136, 140, 188, 196, 208, 181, 198, 209, 168, 197, 197, 100, 111, 110, 136, 134, 136, 172, 192, 204, 181, 197, 204, 1]\n",
            "[116, 132, 136, 137, 138, 126, 141, 134, 130, 140, 136, 129, 138, 133, 129, 143, 139, 132, 139, 135, 128, 141, 137, 130, 137, 133, 127, 135, 134, 124, 138, 132, 126, 138, 133, 125, 134, 135, 128, 138, 136, 126, 136, 132, 125, 140, 137, 127, 1]\n",
            "[143, 154, 154, 144, 154, 155, 142, 154, 155, 57, 154, 146, 143, 154, 155, 148, 154, 155, 147, 154, 155, 128, 154, 69, 142, 154, 155, 141, 154, 155, 144, 154, 155, 57, 154, 145, 146, 154, 155, 144, 154, 155, 57, 154, 155, 57, 154, 147, 1]\n",
            "[134, 140, 134, 136, 133, 141, 136, 133, 118, 129, 145, 137, 122, 149, 146, 129, 135, 129, 136, 140, 130, 131, 147, 136, 148, 135, 144, 138, 147, 139, 136, 142, 141, 136, 142, 136, 136, 145, 141, 136, 147, 141, 136, 147, 141, 136, 133, 134, 1]\n",
            "[199, 208, 190, 197, 208, 190, 192, 214, 195, 200, 209, 192, 186, 196, 181, 190, 202, 185, 187, 198, 186, 193, 207, 191, 192, 201, 183, 170, 184, 173, 243, 233, 177, 177, 188, 179, 11, 3, 0, 17, 6, 0, 13, 4, 0, 20, 12, 0, 1]\n",
            "[142, 133, 143, 131, 122, 130, 122, 118, 125, 122, 115, 123, 142, 135, 130, 131, 122, 130, 131, 122, 130, 122, 115, 123, 142, 122, 121, 131, 122, 127, 133, 122, 134, 109, 122, 134, 142, 135, 134, 131, 122, 130, 129, 124, 132, 131, 122, 112, 1]\n",
            "[128, 166, 126, 118, 166, 126, 161, 166, 126, 161, 166, 158, 118, 166, 126, 118, 166, 126, 161, 166, 126, 118, 169, 151, 128, 166, 126, 119, 166, 126, 118, 166, 126, 118, 166, 126, 119, 166, 126, 119, 166, 126, 118, 166, 126, 118, 166, 126, 1]\n",
            "[15, 190, 172, 92, 113, 113, 15, 113, 113, 72, 113, 133, 14, 52, 72, 52, 72, 72, 14, 113, 113, 113, 170, 194, 14, 52, 50, 32, 72, 72, 92, 113, 113, 133, 173, 194, 15, 52, 72, 15, 52, 50, 92, 113, 113, 133, 173, 194, 1]\n",
            "[32, 32, 32, 32, 32, 29, 32, 32, 22, 24, 32, 22, 32, 52, 37, 32, 39, 32, 32, 32, 29, 32, 32, 22, 32, 32, 32, 32, 32, 29, 25, 32, 22, 21, 32, 22, 13, 16, 17, 32, 19, 17, 32, 32, 22, 21, 32, 22, 1]\n",
            "[113, 133, 113, 130, 153, 155, 249, 173, 249, 248, 249, 17, 130, 170, 160, 153, 173, 169, 248, 249, 249, 173, 173, 194, 153, 173, 171, 250, 173, 17, 249, 249, 17, 173, 190, 194, 153, 173, 172, 173, 173, 182, 153, 173, 183, 181, 194, 194, 1]\n",
            "[72, 92, 72, 248, 248, 249, 52, 52, 50, 52, 52, 50, 72, 72, 72, 248, 249, 250, 32, 52, 50, 32, 52, 50, 52, 52, 50, 52, 72, 72, 32, 249, 17, 32, 52, 37, 52, 52, 50, 32, 52, 37, 32, 248, 250, 32, 52, 37, 1]\n",
            "[118, 133, 146, 125, 141, 156, 124, 141, 157, 127, 144, 159, 122, 136, 149, 132, 149, 166, 127, 145, 158, 132, 150, 166, 122, 140, 153, 128, 146, 163, 127, 144, 162, 153, 163, 172, 127, 144, 158, 129, 148, 165, 128, 147, 162, 153, 163, 173, 1]\n",
            "[72, 92, 92, 72, 92, 72, 72, 92, 72, 72, 92, 250, 72, 92, 72, 32, 32, 17, 72, 92, 72, 214, 249, 250, 72, 92, 72, 249, 249, 249, 250, 72, 72, 173, 72, 72, 72, 92, 72, 52, 72, 72, 52, 72, 50, 52, 72, 72, 1]\n",
            "[131, 148, 164, 130, 147, 163, 128, 143, 162, 128, 142, 154, 128, 144, 156, 131, 144, 163, 130, 145, 162, 129, 143, 152, 125, 141, 156, 135, 152, 166, 131, 146, 54, 128, 142, 154, 133, 151, 170, 133, 150, 165, 135, 151, 169, 127, 141, 152, 1]\n",
            "[153, 170, 194, 250, 250, 249, 130, 153, 163, 130, 170, 164, 250, 250, 250, 249, 249, 249, 250, 153, 250, 130, 145, 141, 133, 153, 167, 249, 249, 249, 113, 145, 150, 113, 133, 133, 130, 153, 161, 113, 145, 150, 248, 248, 248, 249, 247, 133, 1]\n",
            "[130, 133, 133, 113, 248, 133, 130, 153, 148, 133, 249, 17, 130, 153, 144, 130, 249, 249, 133, 153, 17, 133, 153, 153, 130, 153, 151, 133, 145, 146, 133, 153, 151, 133, 153, 153, 153, 153, 161, 133, 153, 158, 153, 153, 159, 133, 153, 161, 1]\n",
            "[92, 113, 92, 250, 250, 250, 72, 72, 72, 52, 72, 52, 92, 92, 92, 249, 249, 250, 72, 92, 72, 52, 52, 50, 92, 92, 92, 72, 92, 72, 248, 248, 17, 32, 52, 37, 92, 92, 92, 72, 92, 72, 248, 249, 249, 32, 52, 37, 1]\n",
            "[139, 154, 165, 139, 157, 166, 146, 160, 167, 206, 192, 212, 138, 152, 155, 134, 0, 0, 36, 13, 5, 131, 139, 0, 136, 149, 157, 138, 21, 151, 122, 120, 123, 21, 0, 0, 138, 154, 160, 136, 155, 165, 123, 136, 136, 36, 13, 0, 1]\n",
            "[152, 170, 165, 172, 170, 172, 181, 190, 193, 172, 190, 172, 152, 172, 172, 152, 170, 172, 172, 170, 172, 172, 172, 172, 152, 152, 172, 17, 21, 13, 18, 170, 17, 172, 170, 172, 17, 19, 13, 152, 170, 172, 172, 172, 172, 172, 190, 172, 1]\n",
            "[141, 156, 166, 138, 156, 167, 142, 151, 152, 143, 157, 161, 141, 158, 162, 138, 145, 149, 142, 154, 152, 129, 152, 156, 145, 160, 163, 158, 253, 165, 129, 146, 157, 122, 138, 147, 229, 229, 234, 132, 149, 165, 125, 141, 147, 115, 128, 139, 1]\n",
            "[181, 206, 194, 92, 133, 133, 130, 133, 133, 130, 133, 133, 17, 113, 17, 113, 113, 124, 133, 133, 133, 130, 145, 135, 17, 22, 17, 113, 133, 17, 217, 226, 222, 214, 145, 133, 17, 22, 17, 220, 232, 222, 113, 113, 133, 17, 113, 13, 1]\n",
            "[249, 249, 249, 248, 249, 248, 173, 190, 194, 181, 194, 194, 153, 170, 173, 248, 248, 248, 249, 194, 194, 181, 194, 194, 92, 133, 133, 249, 249, 194, 248, 249, 249, 181, 194, 194, 153, 194, 194, 181, 206, 194, 181, 206, 194, 72, 194, 72, 1]\n",
            "[130, 153, 152, 250, 250, 250, 113, 133, 133, 113, 133, 133, 248, 249, 248, 250, 250, 250, 17, 250, 17, 130, 145, 147, 153, 153, 163, 248, 250, 248, 250, 249, 250, 133, 153, 160, 153, 170, 170, 153, 170, 166, 250, 170, 167, 181, 194, 194, 1]\n",
            "[127, 140, 147, 115, 129, 137, 126, 137, 147, 126, 140, 148, 122, 134, 141, 96, 99, 112, 15, 94, 106, 125, 136, 145, 123, 131, 140, 100, 93, 103, 107, 96, 105, 127, 137, 143, 111, 121, 131, 123, 114, 120, 104, 111, 117, 107, 117, 127, 1]\n",
            "[130, 153, 151, 248, 249, 249, 249, 249, 248, 249, 249, 17, 248, 248, 248, 249, 249, 249, 113, 133, 133, 249, 249, 17, 130, 145, 140, 130, 145, 133, 113, 145, 133, 113, 133, 133, 173, 170, 175, 173, 190, 179, 173, 190, 187, 173, 190, 182, 1]\n",
            "[122, 144, 191, 56, 64, 79, 97, 115, 134, 100, 122, 141, 54, 63, 77, 71, 78, 93, 73, 86, 101, 105, 123, 143, 65, 64, 78, 64, 75, 91, 70, 79, 94, 78, 161, 147, 69, 81, 97, 71, 81, 96, 76, 88, 102, 75, 89, 104, 1]\n",
            "[173, 190, 194, 249, 249, 249, 248, 249, 248, 15, 19, 17, 173, 190, 180, 153, 170, 170, 250, 249, 250, 250, 250, 250, 173, 190, 178, 153, 170, 17, 248, 249, 248, 250, 250, 17, 153, 173, 179, 249, 249, 249, 249, 249, 249, 133, 170, 17, 1]\n",
            "[130, 153, 142, 113, 133, 133, 113, 133, 133, 130, 170, 242, 133, 153, 144, 249, 249, 17, 249, 248, 17, 130, 153, 151, 133, 153, 150, 130, 153, 153, 113, 153, 17, 249, 249, 17, 153, 173, 17, 17, 248, 17, 113, 145, 156, 249, 247, 240, 1]\n",
            "[139, 155, 162, 157, 172, 185, 159, 173, 185, 164, 177, 191, 113, 122, 125, 165, 185, 194, 169, 255, 200, 168, 186, 197, 106, 122, 119, 102, 122, 107, 255, 255, 251, 194, 207, 210, 105, 119, 113, 108, 120, 183, 183, 193, 195, 188, 197, 203, 1]\n",
            "[123, 149, 174, 123, 148, 173, 149, 151, 145, 133, 152, 180, 127, 149, 172, 116, 148, 240, 89, 105, 239, 86, 153, 129, 108, 144, 172, 99, 146, 172, 184, 223, 238, 79, 101, 185, 143, 157, 181, 138, 160, 183, 142, 162, 185, 144, 166, 189, 1]\n",
            "[94, 100, 113, 104, 112, 124, 105, 113, 125, 71, 86, 103, 112, 120, 133, 95, 103, 117, 103, 111, 125, 106, 113, 126, 113, 120, 133, 113, 121, 134, 99, 100, 119, 105, 112, 126, 147, 162, 184, 113, 121, 132, 114, 122, 133, 98, 107, 119, 1]\n",
            "[118, 119, 136, 134, 143, 168, 130, 150, 165, 130, 150, 168, 119, 128, 134, 132, 145, 157, 132, 149, 164, 133, 150, 169, 114, 126, 135, 111, 120, 133, 116, 134, 146, 127, 146, 157, 107, 122, 132, 97, 105, 116, 93, 97, 109, 115, 134, 149, 1]\n",
            "[123, 142, 161, 121, 140, 160, 126, 143, 160, 130, 148, 165, 130, 145, 161, 127, 145, 163, 123, 141, 159, 131, 148, 167, 126, 140, 154, 129, 150, 162, 123, 141, 160, 129, 148, 163, 125, 139, 154, 120, 136, 148, 125, 142, 161, 130, 147, 160, 1]\n",
            "[92, 133, 133, 72, 92, 113, 92, 133, 113, 92, 92, 72, 113, 133, 133, 72, 113, 113, 249, 249, 249, 72, 92, 92, 92, 133, 133, 92, 133, 133, 248, 249, 248, 92, 92, 92, 92, 133, 133, 92, 133, 133, 248, 249, 248, 72, 92, 72, 1]\n",
            "[113, 145, 133, 130, 170, 164, 130, 153, 152, 92, 128, 133, 113, 133, 133, 113, 153, 153, 113, 145, 133, 92, 113, 127, 113, 133, 133, 113, 145, 154, 113, 133, 133, 92, 113, 113, 72, 92, 92, 92, 113, 113, 92, 113, 113, 92, 113, 113, 1]\n",
            "[92, 113, 113, 113, 133, 133, 113, 153, 155, 92, 113, 92, 113, 145, 133, 248, 250, 249, 249, 249, 248, 113, 145, 142, 130, 153, 153, 250, 250, 249, 130, 145, 146, 113, 145, 133, 113, 153, 133, 130, 145, 138, 130, 145, 133, 113, 145, 133, 1]\n",
            "[158, 165, 170, 80, 100, 84, 80, 100, 86, 78, 95, 82, 128, 162, 165, 152, 161, 169, 82, 98, 87, 82, 100, 87, 91, 109, 100, 128, 134, 138, 163, 167, 172, 132, 136, 91, 93, 107, 98, 91, 105, 97, 135, 139, 172, 163, 167, 172, 1]\n",
            "[139, 155, 166, 138, 154, 165, 136, 157, 166, 139, 154, 165, 131, 136, 147, 136, 151, 158, 131, 143, 149, 138, 151, 149, 149, 170, 169, 141, 158, 166, 136, 149, 157, 141, 154, 161, 131, 139, 143, 131, 145, 150, 135, 143, 160, 136, 152, 158, 1]\n",
            "[173, 173, 172, 153, 173, 172, 133, 153, 159, 113, 133, 133, 153, 173, 172, 133, 145, 144, 133, 145, 160, 133, 153, 146, 133, 173, 162, 248, 248, 243, 250, 247, 17, 133, 247, 17, 133, 153, 158, 133, 153, 155, 130, 133, 133, 17, 19, 17, 1]\n",
            "[153, 170, 170, 32, 145, 50, 32, 52, 52, 113, 145, 133, 153, 173, 170, 240, 247, 238, 32, 52, 50, 133, 153, 155, 113, 145, 133, 113, 133, 133, 240, 247, 238, 113, 145, 151, 113, 133, 133, 113, 145, 133, 113, 145, 133, 234, 242, 17, 1]\n",
            "[130, 153, 151, 14, 92, 17, 92, 113, 17, 113, 133, 17, 130, 153, 149, 130, 145, 133, 234, 248, 242, 214, 234, 241, 130, 145, 133, 17, 133, 17, 238, 249, 17, 113, 145, 133, 130, 153, 151, 130, 248, 156, 113, 133, 133, 113, 133, 133, 1]\n",
            "[248, 248, 248, 72, 113, 113, 72, 113, 113, 72, 92, 72, 248, 248, 249, 72, 92, 92, 72, 92, 72, 248, 248, 250, 248, 250, 250, 249, 249, 249, 72, 92, 92, 113, 145, 133, 72, 92, 72, 72, 72, 72, 72, 92, 92, 113, 145, 133, 1]\n",
            "[138, 158, 183, 187, 198, 206, 139, 160, 184, 141, 162, 185, 136, 155, 178, 187, 159, 185, 142, 163, 237, 185, 195, 182, 103, 120, 143, 188, 201, 214, 140, 162, 187, 138, 159, 182, 104, 124, 145, 123, 150, 175, 187, 200, 211, 133, 153, 230, 1]\n",
            "[111, 126, 143, 106, 121, 141, 95, 107, 125, 79, 110, 129, 108, 121, 140, 152, 176, 205, 67, 97, 117, 97, 109, 126, 147, 172, 141, 63, 71, 88, 65, 75, 94, 125, 134, 150, 56, 65, 82, 69, 80, 96, 117, 125, 143, 118, 128, 146, 1]\n",
            "[173, 194, 194, 181, 194, 194, 194, 206, 214, 72, 113, 113, 173, 190, 194, 153, 194, 194, 248, 249, 248, 153, 170, 194, 248, 249, 17, 250, 250, 250, 250, 250, 250, 194, 206, 214, 181, 194, 17, 173, 173, 194, 181, 194, 194, 214, 220, 214, 1]\n",
            "[72, 113, 113, 113, 133, 133, 92, 113, 238, 240, 247, 240, 113, 113, 113, 92, 133, 133, 113, 153, 151, 240, 247, 241, 113, 133, 133, 17, 234, 17, 113, 113, 113, 113, 170, 237, 130, 145, 133, 92, 113, 113, 113, 113, 113, 130, 145, 139, 1]\n",
            "[113, 145, 133, 113, 145, 133, 153, 170, 161, 133, 153, 144, 113, 145, 133, 113, 145, 113, 249, 249, 17, 133, 153, 145, 153, 173, 165, 249, 249, 249, 249, 249, 243, 250, 250, 17, 248, 249, 17, 17, 22, 17, 17, 17, 17, 15, 145, 17, 1]\n",
            "[113, 133, 113, 130, 170, 250, 130, 248, 250, 113, 170, 133, 153, 206, 227, 249, 153, 250, 130, 153, 150, 249, 249, 250, 214, 234, 250, 130, 153, 147, 113, 145, 133, 130, 153, 148, 248, 248, 249, 113, 145, 133, 113, 133, 133, 113, 133, 133, 1]\n",
            "[131, 148, 164, 128, 144, 161, 129, 143, 158, 136, 149, 163, 131, 148, 165, 138, 150, 166, 136, 149, 165, 119, 136, 149, 129, 148, 166, 127, 145, 167, 127, 143, 160, 118, 135, 150, 129, 147, 166, 127, 145, 162, 126, 143, 159, 123, 140, 153, 1]\n",
            "[173, 194, 194, 16, 32, 17, 16, 113, 113, 113, 133, 133, 173, 194, 194, 181, 199, 194, 16, 201, 17, 173, 194, 92, 181, 201, 197, 214, 206, 200, 214, 206, 203, 214, 206, 203, 17, 32, 202, 32, 206, 202, 17, 206, 22, 113, 133, 133, 1]\n",
            "[163, 173, 174, 168, 185, 186, 100, 111, 107, 88, 104, 98, 93, 104, 145, 172, 185, 188, 134, 138, 143, 88, 102, 101, 92, 107, 98, 93, 104, 103, 173, 178, 181, 136, 184, 188, 91, 109, 98, 91, 109, 101, 93, 102, 96, 173, 185, 188, 1]\n",
            "[151, 172, 185, 147, 170, 171, 151, 185, 185, 147, 167, 185, 166, 185, 192, 145, 166, 185, 146, 167, 176, 151, 173, 185, 253, 253, 185, 253, 253, 164, 139, 156, 165, 149, 166, 179, 139, 151, 155, 149, 162, 185, 143, 164, 172, 141, 161, 170, 1]\n",
            "[113, 133, 133, 92, 113, 113, 113, 133, 133, 130, 153, 148, 113, 153, 133, 17, 92, 17, 92, 113, 17, 130, 153, 147, 133, 153, 154, 113, 113, 133, 113, 145, 133, 130, 247, 147, 153, 170, 178, 133, 153, 150, 113, 145, 133, 72, 113, 113, 1]\n",
            "[132, 152, 151, 112, 152, 145, 112, 152, 152, 71, 132, 112, 132, 152, 154, 132, 152, 149, 249, 249, 249, 249, 249, 249, 132, 152, 148, 250, 248, 250, 249, 249, 250, 249, 249, 249, 31, 44, 31, 130, 152, 146, 130, 152, 149, 249, 249, 249, 1]\n",
            "[132, 145, 132, 132, 152, 13, 130, 248, 248, 249, 249, 249, 31, 31, 22, 132, 152, 146, 249, 249, 249, 130, 152, 248, 31, 51, 50, 31, 248, 13, 132, 152, 158, 112, 145, 152, 31, 51, 50, 31, 71, 71, 130, 152, 158, 130, 152, 172, 1]\n",
            "[113, 133, 133, 113, 133, 133, 113, 133, 133, 72, 113, 113, 113, 133, 133, 113, 133, 133, 249, 249, 17, 72, 113, 113, 113, 133, 133, 113, 133, 133, 248, 250, 113, 72, 113, 113, 113, 145, 133, 113, 133, 133, 92, 113, 113, 72, 113, 113, 1]\n",
            "[112, 121, 130, 106, 115, 126, 117, 132, 131, 105, 115, 129, 121, 137, 153, 116, 136, 153, 121, 140, 158, 121, 140, 159, 118, 137, 151, 121, 140, 253, 123, 142, 161, 125, 146, 166, 122, 139, 161, 119, 136, 149, 153, 164, 176, 156, 166, 178, 1]\n",
            "[240, 247, 242, 113, 133, 133, 113, 145, 133, 113, 145, 133, 15, 32, 72, 240, 247, 17, 240, 113, 133, 92, 133, 133, 17, 32, 17, 92, 113, 92, 92, 113, 133, 113, 145, 133, 113, 133, 133, 113, 133, 133, 113, 145, 133, 153, 170, 172, 1]\n",
            "[130, 145, 133, 130, 133, 133, 52, 52, 50, 32, 32, 32, 130, 145, 147, 130, 145, 133, 130, 145, 50, 32, 52, 37, 130, 153, 150, 248, 249, 133, 248, 145, 133, 32, 40, 37, 20, 22, 17, 17, 18, 17, 16, 21, 17, 16, 19, 17, 1]\n",
            "[52, 72, 72, 32, 52, 50, 20, 32, 29, 21, 32, 37, 21, 22, 17, 17, 22, 17, 17, 21, 17, 17, 22, 17, 52, 92, 17, 52, 92, 17, 17, 92, 17, 52, 92, 17, 130, 145, 149, 113, 145, 150, 113, 145, 153, 113, 133, 150, 1]\n",
            "[130, 148, 165, 136, 150, 167, 129, 147, 165, 120, 140, 157, 131, 148, 167, 136, 154, 172, 131, 147, 165, 127, 144, 159, 129, 148, 163, 136, 155, 172, 128, 147, 164, 128, 145, 160, 130, 147, 160, 128, 146, 161, 129, 147, 163, 125, 141, 158, 1]\n",
            "[146, 166, 176, 142, 160, 172, 146, 255, 255, 240, 255, 255, 144, 162, 176, 148, 168, 184, 150, 168, 180, 144, 164, 182, 142, 162, 178, 150, 168, 184, 146, 164, 182, 128, 152, 164, 140, 160, 172, 144, 164, 178, 142, 158, 172, 132, 156, 172, 1]\n",
            "[92, 104, 133, 113, 145, 133, 113, 145, 147, 113, 145, 133, 250, 250, 250, 249, 249, 250, 248, 248, 248, 249, 249, 249, 72, 92, 92, 113, 145, 133, 113, 153, 149, 113, 153, 151, 72, 92, 92, 92, 133, 113, 92, 133, 133, 92, 133, 133, 1]\n",
            "[120, 139, 155, 117, 140, 155, 124, 141, 156, 123, 141, 156, 124, 143, 157, 121, 140, 156, 125, 143, 159, 122, 140, 153, 127, 145, 160, 123, 143, 160, 122, 141, 157, 121, 139, 153, 128, 143, 158, 125, 141, 156, 121, 139, 154, 120, 138, 150, 1]\n",
            "[160, 179, 185, 154, 173, 185, 155, 174, 185, 246, 248, 247, 145, 160, 169, 152, 167, 185, 149, 169, 178, 162, 185, 185, 132, 143, 155, 139, 151, 161, 138, 154, 162, 146, 167, 185, 145, 160, 172, 136, 152, 161, 136, 151, 161, 146, 164, 174, 1]\n",
            "[130, 151, 172, 128, 149, 170, 129, 150, 170, 129, 151, 173, 129, 150, 170, 130, 151, 171, 128, 150, 171, 129, 151, 172, 134, 152, 172, 129, 152, 172, 134, 153, 174, 130, 153, 173, 130, 149, 171, 130, 150, 171, 129, 150, 170, 130, 151, 171, 1]\n",
            "[248, 249, 249, 153, 173, 173, 173, 190, 194, 52, 92, 72, 153, 173, 172, 250, 250, 250, 133, 170, 17, 52, 170, 72, 153, 173, 172, 250, 250, 250, 248, 249, 248, 181, 206, 194, 133, 145, 17, 153, 173, 174, 173, 190, 194, 153, 153, 162, 1]\n",
            "[167, 188, 207, 103, 115, 255, 114, 122, 135, 118, 131, 143, 125, 143, 160, 125, 145, 157, 122, 140, 154, 123, 139, 142, 128, 146, 165, 127, 146, 163, 124, 144, 158, 126, 139, 148, 157, 167, 181, 127, 144, 157, 120, 139, 154, 122, 135, 148, 1]\n",
            "[141, 163, 171, 138, 161, 171, 146, 166, 176, 142, 166, 178, 138, 158, 163, 136, 157, 167, 142, 163, 173, 141, 161, 169, 135, 154, 157, 138, 151, 166, 143, 162, 173, 134, 151, 161, 138, 156, 161, 146, 166, 185, 149, 173, 185, 149, 174, 185, 1]\n",
            "[131, 152, 176, 136, 158, 178, 135, 157, 180, 130, 151, 173, 134, 156, 178, 137, 156, 177, 137, 158, 180, 136, 159, 181, 135, 157, 178, 139, 159, 179, 137, 158, 180, 138, 160, 182, 137, 157, 178, 140, 159, 182, 139, 163, 184, 138, 160, 182, 1]\n",
            "[119, 136, 147, 127, 146, 162, 129, 150, 165, 127, 145, 161, 123, 136, 147, 131, 144, 160, 131, 152, 166, 134, 152, 168, 118, 126, 137, 131, 147, 160, 139, 148, 165, 132, 151, 165, 113, 119, 130, 128, 143, 154, 132, 150, 164, 131, 151, 168, 1]\n",
            "[160, 177, 194, 155, 173, 190, 150, 165, 178, 150, 167, 181, 157, 175, 189, 153, 172, 186, 148, 169, 182, 115, 127, 138, 155, 172, 190, 153, 170, 188, 148, 163, 176, 142, 161, 176, 157, 174, 191, 157, 174, 188, 151, 167, 183, 150, 165, 181, 1]\n",
            "[101, 117, 135, 146, 165, 183, 145, 166, 181, 163, 181, 201, 147, 168, 185, 148, 167, 184, 148, 164, 169, 158, 177, 196, 146, 166, 171, 166, 186, 206, 161, 178, 198, 160, 180, 201, 140, 158, 171, 162, 184, 203, 162, 181, 198, 150, 167, 183, 1]\n",
            "[159, 179, 198, 159, 178, 193, 158, 175, 191, 161, 182, 186, 150, 165, 180, 149, 165, 182, 157, 175, 190, 156, 172, 186, 154, 167, 178, 147, 162, 175, 140, 152, 253, 152, 170, 184, 153, 172, 183, 149, 165, 177, 146, 167, 181, 123, 137, 64, 1]\n",
            "[106, 120, 137, 103, 118, 135, 104, 118, 136, 104, 117, 135, 102, 116, 133, 105, 119, 136, 102, 115, 133, 101, 114, 131, 103, 116, 134, 100, 114, 132, 100, 115, 133, 95, 108, 126, 95, 109, 127, 99, 111, 130, 99, 112, 130, 99, 111, 129, 1]\n",
            "[98, 113, 131, 133, 155, 177, 134, 155, 177, 141, 162, 183, 102, 119, 138, 133, 155, 177, 134, 156, 177, 135, 156, 178, 134, 157, 178, 135, 157, 175, 135, 156, 176, 135, 159, 180, 139, 160, 180, 137, 158, 178, 137, 159, 180, 83, 96, 113, 1]\n",
            "[151, 167, 183, 149, 164, 182, 145, 163, 253, 187, 203, 221, 150, 167, 183, 152, 162, 178, 156, 172, 184, 123, 135, 136, 143, 154, 164, 155, 169, 187, 155, 173, 187, 149, 166, 185, 151, 165, 174, 143, 157, 165, 157, 175, 193, 155, 175, 186, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the csv file is ready to be used for MLP Classification"
      ],
      "metadata": {
        "id": "uzLFdddACmww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using **MLP Classifier**"
      ],
      "metadata": {
        "id": "mf703nlYCsMw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the dependencies"
      ],
      "metadata": {
        "id": "raP948LsCvwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "FE8qomGz1sX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/airplanes_agriculture_dataset')\n",
        "x_data=csv_file.iloc[:,0:-1].values\n",
        "y_data=csv_file.iloc[:,-1].values\n",
        "print(\"Shape of X-Data:\",x_data.shape)\n",
        "print(\"Shape of Y-Data:\",y_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFIG9520DJcf",
        "outputId": "d51db1ed-8b38-49e8-8949-f4ea5f04da92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X-Data: (199, 48)\n",
            "Shape of Y-Data: (199,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now making the train test split"
      ],
      "metadata": {
        "id": "qSf3wxitEBx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(x_data,y_data,test_size=0.3,shuffle=True)\n",
        "print(\"x_train.shape:\",x_train.shape)\n",
        "print(\"y_train.shape\",y_train.shape)\n",
        "print(\"x_test.shape:\",x_test.shape)\n",
        "print(\"y_test.shape:\",y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-usNjH_IEHVP",
        "outputId": "f6670857-e489-4eb9-e509-ea5afeb53f78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train.shape: (139, 48)\n",
            "y_train.shape (139,)\n",
            "x_test.shape: (60, 48)\n",
            "y_test.shape: (60,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now training the MLP Classifier"
      ],
      "metadata": {
        "id": "DfgoKu1nD8Ex"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The default values for the MLPclassifier are ,\n",
        "\n",
        "class sklearn.neural_network.MLPClassifier(hidden_layer_sizes=(100,), activation='relu', *, solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000)"
      ],
      "metadata": {
        "id": "8D2Sv_jiFiNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier=MLPClassifier(hidden_layer_sizes=(100,50,10),learning_rate_init=0.0001,max_iter=600)\n",
        "classifier.fit(x_train,y_train)\n",
        "prediction=classifier.predict(x_test)\n",
        "print(\"Prediction.shape:\",prediction.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAcqgdhqFPTf",
        "outputId": "78e646aa-d04d-4097-e547-52368390366c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction.shape: (60,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now checking the accuracy"
      ],
      "metadata": {
        "id": "-Ydb-LrqGqgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct=0\n",
        "for i in range(y_test.shape[0]):\n",
        "  if (prediction[i]==y_test[0]):\n",
        "    correct+=1\n",
        "\n",
        "print(correct)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpjQX8FVGsr3",
        "outputId": "1e4bb0d5-8dbf-4324-ee64-8d5c213eeb6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy:\",correct*100/prediction.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9rdKqyVLhuw",
        "outputId": "ba5e3293-20a1-478a-c505-520012d1e089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 43.333333333333336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now trying to implement **FFNN** with pytorch"
      ],
      "metadata": {
        "id": "veMVsj02P1cp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "Y7g1hdYfP9hQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the model for **FFNN**"
      ],
      "metadata": {
        "id": "TlufZHyWQKR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Excel file with the features and class labels\n",
        "data_path = \"/content/drive/MyDrive/Colab Notebooks/Data/airplanes_agriculture_dataset\"\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes=2)\n",
        "y_test = to_categorical(y_test, num_classes=2)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(32, activation='relu', input_shape=(48,)))\n",
        "\n",
        "model.add(Dense(16, activation='relu'))\n",
        "\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=10, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "\n",
        "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "id": "ZGUaynaHQJPA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89ff3e28-c02b-48b8-894f-708199d2c166"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.4803 - loss: 1.0806 - val_accuracy: 0.5500 - val_loss: 0.7574\n",
            "Epoch 2/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4883 - loss: 0.8322 - val_accuracy: 0.6000 - val_loss: 0.6801\n",
            "Epoch 3/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5671 - loss: 0.7029 - val_accuracy: 0.6250 - val_loss: 0.6515\n",
            "Epoch 4/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5767 - loss: 0.6871 - val_accuracy: 0.6000 - val_loss: 0.6424\n",
            "Epoch 5/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6524 - loss: 0.6228 - val_accuracy: 0.5750 - val_loss: 0.6398\n",
            "Epoch 6/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6726 - loss: 0.5893 - val_accuracy: 0.6250 - val_loss: 0.6370\n",
            "Epoch 7/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6396 - loss: 0.5327 - val_accuracy: 0.6250 - val_loss: 0.6253\n",
            "Epoch 8/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7783 - loss: 0.4695 - val_accuracy: 0.6000 - val_loss: 0.6322\n",
            "Epoch 9/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7968 - loss: 0.5037 - val_accuracy: 0.6500 - val_loss: 0.6161\n",
            "Epoch 10/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8612 - loss: 0.4267 - val_accuracy: 0.6000 - val_loss: 0.6313\n",
            "Epoch 11/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4365 - val_accuracy: 0.6500 - val_loss: 0.6231\n",
            "Epoch 12/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8491 - loss: 0.4453 - val_accuracy: 0.6250 - val_loss: 0.6300\n",
            "Epoch 13/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8823 - loss: 0.3799 - val_accuracy: 0.6250 - val_loss: 0.6498\n",
            "Epoch 14/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.3389 - val_accuracy: 0.6750 - val_loss: 0.6417\n",
            "Epoch 15/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9156 - loss: 0.3324 - val_accuracy: 0.7250 - val_loss: 0.6483\n",
            "Epoch 16/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9206 - loss: 0.3312 - val_accuracy: 0.6750 - val_loss: 0.6673\n",
            "Epoch 17/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8655 - loss: 0.3350 - val_accuracy: 0.7250 - val_loss: 0.6801\n",
            "Epoch 18/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9388 - loss: 0.2828 - val_accuracy: 0.7000 - val_loss: 0.7213\n",
            "Epoch 19/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9235 - loss: 0.2707 - val_accuracy: 0.7000 - val_loss: 0.7219\n",
            "Epoch 20/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9458 - loss: 0.2492 - val_accuracy: 0.7000 - val_loss: 0.7554\n",
            "Epoch 21/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9147 - loss: 0.2741 - val_accuracy: 0.7500 - val_loss: 0.7316\n",
            "Epoch 22/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9265 - loss: 0.2955 - val_accuracy: 0.6750 - val_loss: 0.7934\n",
            "Epoch 23/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9298 - loss: 0.2225 - val_accuracy: 0.6500 - val_loss: 0.8082\n",
            "Epoch 24/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9476 - loss: 0.2269 - val_accuracy: 0.7000 - val_loss: 0.8154\n",
            "Epoch 25/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9218 - loss: 0.2224 - val_accuracy: 0.7000 - val_loss: 0.8605\n",
            "Epoch 26/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9463 - loss: 0.1980 - val_accuracy: 0.7000 - val_loss: 0.8865\n",
            "Epoch 27/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9664 - loss: 0.1503 - val_accuracy: 0.7000 - val_loss: 0.8992\n",
            "Epoch 28/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9589 - loss: 0.1537 - val_accuracy: 0.6750 - val_loss: 0.9076\n",
            "Epoch 29/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9365 - loss: 0.1886 - val_accuracy: 0.6500 - val_loss: 0.9173\n",
            "Epoch 30/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9258 - loss: 0.1794 - val_accuracy: 0.6750 - val_loss: 0.9611\n",
            "Epoch 31/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9539 - loss: 0.1579 - val_accuracy: 0.6500 - val_loss: 0.9709\n",
            "Epoch 32/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9596 - loss: 0.1483 - val_accuracy: 0.6750 - val_loss: 1.0083\n",
            "Epoch 33/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9536 - loss: 0.1487 - val_accuracy: 0.6750 - val_loss: 1.0137\n",
            "Epoch 34/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9410 - loss: 0.1339 - val_accuracy: 0.6750 - val_loss: 1.0890\n",
            "Epoch 35/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.1465 - val_accuracy: 0.6750 - val_loss: 1.0644\n",
            "Epoch 36/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9098 - loss: 0.2066 - val_accuracy: 0.6500 - val_loss: 1.0841\n",
            "Epoch 37/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9551 - loss: 0.1517 - val_accuracy: 0.6500 - val_loss: 1.1217\n",
            "Epoch 38/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9451 - loss: 0.1381 - val_accuracy: 0.6500 - val_loss: 1.1338\n",
            "Epoch 39/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9691 - loss: 0.1071 - val_accuracy: 0.6500 - val_loss: 1.1453\n",
            "Epoch 40/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9416 - loss: 0.1390 - val_accuracy: 0.6500 - val_loss: 1.1733\n",
            "Epoch 41/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9545 - loss: 0.1005 - val_accuracy: 0.6500 - val_loss: 1.2456\n",
            "Epoch 42/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9763 - loss: 0.1172 - val_accuracy: 0.6500 - val_loss: 1.2028\n",
            "Epoch 43/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9837 - loss: 0.0687 - val_accuracy: 0.6750 - val_loss: 1.2310\n",
            "Epoch 44/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9720 - loss: 0.1205 - val_accuracy: 0.6750 - val_loss: 1.2482\n",
            "Epoch 45/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9454 - loss: 0.1457 - val_accuracy: 0.7000 - val_loss: 1.2705\n",
            "Epoch 46/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9795 - loss: 0.0929 - val_accuracy: 0.6750 - val_loss: 1.3179\n",
            "Epoch 47/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9750 - loss: 0.0799 - val_accuracy: 0.6750 - val_loss: 1.3062\n",
            "Epoch 48/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9782 - loss: 0.1053 - val_accuracy: 0.7000 - val_loss: 1.3163\n",
            "Epoch 49/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9495 - loss: 0.1295 - val_accuracy: 0.6750 - val_loss: 1.3440\n",
            "Epoch 50/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9823 - loss: 0.0826 - val_accuracy: 0.7000 - val_loss: 1.3733\n",
            "Epoch 51/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9763 - loss: 0.0964 - val_accuracy: 0.6750 - val_loss: 1.3765\n",
            "Epoch 52/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9570 - loss: 0.0851 - val_accuracy: 0.6500 - val_loss: 1.4358\n",
            "Epoch 53/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9834 - loss: 0.0668 - val_accuracy: 0.6750 - val_loss: 1.4443\n",
            "Epoch 54/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9842 - loss: 0.0711 - val_accuracy: 0.6750 - val_loss: 1.4360\n",
            "Epoch 55/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9510 - loss: 0.0874 - val_accuracy: 0.6500 - val_loss: 1.4934\n",
            "Epoch 56/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.1020 - val_accuracy: 0.6750 - val_loss: 1.5154\n",
            "Epoch 57/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9857 - loss: 0.0608 - val_accuracy: 0.6500 - val_loss: 1.5424\n",
            "Epoch 58/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9774 - loss: 0.0718 - val_accuracy: 0.6750 - val_loss: 1.5746\n",
            "Epoch 59/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9879 - loss: 0.0888 - val_accuracy: 0.6750 - val_loss: 1.5765\n",
            "Epoch 60/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9745 - loss: 0.0697 - val_accuracy: 0.6500 - val_loss: 1.6299\n",
            "Epoch 61/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9802 - loss: 0.0788 - val_accuracy: 0.7000 - val_loss: 1.6328\n",
            "Epoch 62/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9448 - loss: 0.1283 - val_accuracy: 0.6750 - val_loss: 1.6230\n",
            "Epoch 63/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9570 - loss: 0.1112 - val_accuracy: 0.6750 - val_loss: 1.6992\n",
            "Epoch 64/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9781 - loss: 0.0562 - val_accuracy: 0.6750 - val_loss: 1.6907\n",
            "Epoch 65/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9855 - loss: 0.0622 - val_accuracy: 0.6500 - val_loss: 1.7113\n",
            "Epoch 66/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9871 - loss: 0.0517 - val_accuracy: 0.6750 - val_loss: 1.7476\n",
            "Epoch 67/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9932 - loss: 0.0477 - val_accuracy: 0.6500 - val_loss: 1.8151\n",
            "Epoch 68/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9684 - loss: 0.0755 - val_accuracy: 0.6500 - val_loss: 1.8222\n",
            "Epoch 69/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9919 - loss: 0.0583 - val_accuracy: 0.6250 - val_loss: 1.8105\n",
            "Epoch 70/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9879 - loss: 0.0673 - val_accuracy: 0.6750 - val_loss: 1.8048\n",
            "Epoch 71/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9913 - loss: 0.0336 - val_accuracy: 0.6750 - val_loss: 1.8586\n",
            "Epoch 72/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9812 - loss: 0.0608 - val_accuracy: 0.6250 - val_loss: 1.8449\n",
            "Epoch 73/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9905 - loss: 0.0446 - val_accuracy: 0.6750 - val_loss: 1.9561\n",
            "Epoch 74/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9976 - loss: 0.0520 - val_accuracy: 0.6500 - val_loss: 1.9242\n",
            "Epoch 75/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9849 - loss: 0.0448 - val_accuracy: 0.6500 - val_loss: 1.9385\n",
            "Epoch 76/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9876 - loss: 0.0482 - val_accuracy: 0.6750 - val_loss: 1.9877\n",
            "Epoch 77/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9931 - loss: 0.0453 - val_accuracy: 0.6250 - val_loss: 1.9581\n",
            "Epoch 78/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9854 - loss: 0.0600 - val_accuracy: 0.6250 - val_loss: 1.9683\n",
            "Epoch 79/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9927 - loss: 0.0401 - val_accuracy: 0.6750 - val_loss: 2.0503\n",
            "Epoch 80/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9863 - loss: 0.0468 - val_accuracy: 0.6500 - val_loss: 2.0436\n",
            "Epoch 81/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9916 - loss: 0.0406 - val_accuracy: 0.6500 - val_loss: 2.1215\n",
            "Epoch 82/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9924 - loss: 0.0526 - val_accuracy: 0.6500 - val_loss: 2.0733\n",
            "Epoch 83/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9858 - loss: 0.0410 - val_accuracy: 0.6500 - val_loss: 2.0991\n",
            "Epoch 84/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9907 - loss: 0.0394 - val_accuracy: 0.6750 - val_loss: 2.0888\n",
            "Epoch 85/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9917 - loss: 0.0470 - val_accuracy: 0.7000 - val_loss: 2.2294\n",
            "Epoch 86/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9935 - loss: 0.0502 - val_accuracy: 0.6750 - val_loss: 2.1522\n",
            "Epoch 87/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9742 - loss: 0.0749 - val_accuracy: 0.6500 - val_loss: 2.1683\n",
            "Epoch 88/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0348 - val_accuracy: 0.7000 - val_loss: 2.2079\n",
            "Epoch 89/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0175 - val_accuracy: 0.6750 - val_loss: 2.1909\n",
            "Epoch 90/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9966 - loss: 0.0242 - val_accuracy: 0.6750 - val_loss: 2.2463\n",
            "Epoch 91/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0302 - val_accuracy: 0.7000 - val_loss: 2.2506\n",
            "Epoch 92/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0251 - val_accuracy: 0.7000 - val_loss: 2.2889\n",
            "Epoch 93/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9843 - loss: 0.0519 - val_accuracy: 0.6750 - val_loss: 2.3223\n",
            "Epoch 94/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9949 - loss: 0.0255 - val_accuracy: 0.7000 - val_loss: 2.3503\n",
            "Epoch 95/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0209 - val_accuracy: 0.7000 - val_loss: 2.4037\n",
            "Epoch 96/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9859 - loss: 0.0372 - val_accuracy: 0.7000 - val_loss: 2.4631\n",
            "Epoch 97/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9909 - loss: 0.0337 - val_accuracy: 0.7000 - val_loss: 2.4129\n",
            "Epoch 98/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9940 - loss: 0.0273 - val_accuracy: 0.7000 - val_loss: 2.4481\n",
            "Epoch 99/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0216 - val_accuracy: 0.7000 - val_loss: 2.4156\n",
            "Epoch 100/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0233 - val_accuracy: 0.7000 - val_loss: 2.5111\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6854 - loss: 2.5743  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7d48c9755f30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.7000\n",
            "\r\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7d48c9755f30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.71      0.71        21\n",
            "           1       0.68      0.68      0.68        19\n",
            "\n",
            "    accuracy                           0.70        40\n",
            "   macro avg       0.70      0.70      0.70        40\n",
            "weighted avg       0.70      0.70      0.70        40\n",
            "\n"
          ]
        }
      ]
    }
  ]
}